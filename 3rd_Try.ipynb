{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3341a86d-27c0-4c74-87f5-d8a34284d6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a12ff23-6733-4478-87bf-9bb4304de344",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yatish\\AppData\\Local\\Temp\\ipykernel_26772\\527562521.py:3: FutureWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
      "  data = pd.read_csv(file_path, delimiter=';', parse_dates={'Datetime': ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['nan','?'])\n",
      "C:\\Users\\yatish\\AppData\\Local\\Temp\\ipykernel_26772\\527562521.py:3: UserWarning: Parsing dates in %d/%m/%Y %H:%M:%S format when dayfirst=False (the default) was specified. Pass `dayfirst=True` or specify a format to silence this warning.\n",
      "  data = pd.read_csv(file_path, delimiter=';', parse_dates={'Datetime': ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['nan','?'])\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "file_path = 'household_power_consumption.txt'  \n",
    "data = pd.read_csv(file_path, delimiter=';', parse_dates={'Datetime': ['Date', 'Time']}, infer_datetime_format=True, low_memory=False, na_values=['nan','?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36efb8d5-c8b2-4818-9c6e-39f8a8015185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Datetime'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26772\\1739292188.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'?'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'Global_active_power'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Global_reactive_power'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Voltage'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Global_intensity'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sub_metering_1'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sub_metering_2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sub_metering_3'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numeric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Datetime'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'hour'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhour\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'day_of_week'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdayofweek\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'month'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmonth\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[0;32m   5869\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5870\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5872\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5873\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5875\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5876\u001b[0m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"None of ['Datetime'] are in the columns\""
     ]
    }
   ],
   "source": [
    "# Handling missing values and data preparation\n",
    "data.replace('?', np.nan, inplace=True)\n",
    "data = data.dropna()\n",
    "cols = ['Global_active_power', 'Global_reactive_power', 'Voltage', 'Global_intensity', 'Sub_metering_1', 'Sub_metering_2', 'Sub_metering_3']\n",
    "data[cols] = data[cols].apply(pd.to_numeric, errors='coerce', axis=1)\n",
    "data.set_index('Datetime', inplace=True)\n",
    "data['hour'] = data.index.hour\n",
    "data['day_of_week'] = data.index.dayofweek\n",
    "data['month'] = data.index.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b777d08b-37c9-40db-b21d-e4be95631742",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Feature and target variables\n",
    "X = data[['hour', 'day_of_week', 'month']]\n",
    "y = data['Global_active_power']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbae0ace-d69a-426d-b47f-a9bcf84fd991",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1baac828-dd95-45e2-83c6-187c679e26b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge_model = Ridge()\n",
    "ridge_params = {'alpha': [1e-3, 1e-2, 1e-1, 1, 10, 100]}\n",
    "ridge_search = GridSearchCV(ridge_model, ridge_params, cv=3, scoring='neg_mean_squared_error')\n",
    "ridge_search.fit(X_train, y_train)\n",
    "best_ridge = ridge_search.best_estimator_\n",
    "ridge_predictions = best_ridge.predict(X_test)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "print(f\"Ridge - Best Params: {ridge_search.best_params_}, RMSE: {ridge_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936833dd-fa90-453b-9e1c-ab891f50480a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gb_model = GradientBoostingRegressor()\n",
    "gb_params = {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 4]}\n",
    "gb_search = GridSearchCV(gb_model, gb_params, cv=3, scoring='neg_mean_squared_error')\n",
    "gb_search.fit(X_train, y_train)\n",
    "best_gb = gb_search.best_estimator_\n",
    "gb_predictions = best_gb.predict(X_test)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_predictions))\n",
    "print(f\"GradientBoosting - Best Params: {gb_search.best_params_}, RMSE: {gb_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0058a1bc-e1f3-4204-8a25-c08d488a1385",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_model = RandomForestRegressor()\n",
    "rf_params = {'n_estimators': [100, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 10]}\n",
    "rf_search = RandomizedSearchCV(rf_model, rf_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "best_rf = rf_search.best_estimator_\n",
    "rf_predictions = best_rf.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"RandomForest - Best Params: {rf_search.best_params_}, RMSE: {rf_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d10386-6f4e-4200-892e-81f47d61d2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "svr_model = SVR()\n",
    "svr_params = {'C': [0.1, 1], 'gamma': [1, 0.1], 'kernel': ['rbf', 'poly']}\n",
    "svr_search = RandomizedSearchCV(svr_model, svr_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "svr_search.fit(X_train, y_train)\n",
    "best_svr = svr_search.best_estimator_\n",
    "svr_predictions = best_svr.predict(X_test)\n",
    "svr_rmse = np.sqrt(mean_squared_error(y_test, svr_predictions))\n",
    "print(f\"SVR - Best Params: {svr_search.best_params_}, RMSE: {svr_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1b3f51-6b86-426a-a278-159b23bf0194",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mlp_model = MLPRegressor()\n",
    "mlp_params = {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh'], 'solver': ['adam'], 'alpha': [0.0001, 0.05]}\n",
    "mlp_search = RandomizedSearchCV(mlp_model, mlp_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "mlp_search.fit(X_train, y_train)\n",
    "best_mlp = mlp_search.best_estimator_\n",
    "mlp_predictions = best_mlp.predict(X_test)\n",
    "mlp_rmse = np.sqrt(mean_squared_error(y_test, mlp_predictions))\n",
    "print(f\"MLPRegressor - Best Params: {mlp_search.best_params_}, RMSE: {mlp_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd819ac-e7fb-42a0-83c6-ef9a56400950",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ARIMA Model\n",
    "arima_model = ARIMA(y_train, order=(5,1,0))\n",
    "arima_model_fit = arima_model.fit()\n",
    "arima_predictions = arima_model_fit.forecast(steps=len(y_test))\n",
    "arima_rmse = np.sqrt(mean_squared_error(y_test, arima_predictions))\n",
    "print(f\"ARIMA RMSE: {arima_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab66f0f4-768b-486f-9445-8cd3b4e55c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LSTM Model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(50, activation='relu', input_shape=(X_train.shape[1], 1)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(optimizer='adam', loss='mse')\n",
    "lstm_model.fit(X_train, y_train, epochs=50, batch_size=72, validation_data=(X_test, y_test), verbose=2)\n",
    "lstm_predictions = lstm_model.predict(X_test).flatten()\n",
    "lstm_rmse = np.sqrt(mean_squared_error(y_test, lstm_predictions))\n",
    "print(f\"LSTM RMSE: {lstm_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a136c22f-1cec-40c5-9c64-dd4d3ef892c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "69 fits failed out of a total of 150.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "13 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "56 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [-0.75788712         nan         nan         nan -0.75793071 -0.77190631\n",
      " -0.75792117 -0.77252047 -0.75793168 -0.75790972         nan -0.7579459\n",
      "         nan         nan         nan -0.77201462 -0.75787929 -0.75791213\n",
      " -0.75791988         nan         nan         nan         nan         nan\n",
      " -0.7718933  -0.75790245 -0.75792553         nan         nan -0.75792351\n",
      " -0.75789327         nan         nan -0.75789353         nan         nan\n",
      " -0.77165459 -0.77177165         nan -0.75793704         nan -0.75788381\n",
      " -0.75791291 -0.757934           nan -0.77181327 -0.75794888         nan\n",
      " -0.75789426         nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Best Params: {'n_estimators': 300, 'min_samples_split': 6, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20}, RMSE: 0.8727657225945454\n",
      "GradientBoosting - Best Params: {'subsample': 1.0, 'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}, RMSE: 0.8770743603644845\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# RandomForest\n",
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_features': ['auto', 'sqrt'],\n",
    "    'max_depth': [10, 15, 20],\n",
    "    'min_samples_split': [2, 4, 6],\n",
    "    'min_samples_leaf': [1, 2, 3]\n",
    "}\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_search = RandomizedSearchCV(rf_model, rf_params, n_iter=50, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "rf_search.fit(X_train, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "rf_predictions = rf_best.predict(X_test)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"RandomForest - Best Params: {rf_search.best_params_}, RMSE: {rf_rmse}\")\n",
    "\n",
    "# GradientBoosting\n",
    "gb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_search = RandomizedSearchCV(gb_model, gb_params, n_iter=50, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "gb_search.fit(X_train, y_train)\n",
    "gb_best = gb_search.best_estimator_\n",
    "gb_predictions = gb_best.predict(X_test)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_predictions))\n",
    "print(f\"GradientBoosting - Best Params: {gb_search.best_params_}, RMSE: {gb_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ca5edf2-7a22-4f24-8161-1c2093fa7ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge - Best Params: {'alpha': 1000.0}, RMSE: 1.0134337668675093\n"
     ]
    }
   ],
   "source": [
    "ridge_model = Ridge()\n",
    "ridge_params = {'alpha': np.logspace(-3, 3, 50)}\n",
    "ridge_search = GridSearchCV(ridge_model, ridge_params, cv=3, scoring='neg_mean_squared_error')\n",
    "ridge_search.fit(X_train, y_train)\n",
    "ridge_best = ridge_search.best_estimator_\n",
    "ridge_predictions = ridge_best.predict(X_test)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "print(f\"Ridge - Best Params: {ridge_search.best_params_}, RMSE: {ridge_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d195a80-9d1e-4687-9bc0-06ff12be4731",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed759ba9-7275-47ee-a4b5-bce497428b0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking RMSE: 0.8727982928004514\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "\n",
    "estimators = [\n",
    "    ('rf', RandomForestRegressor(n_estimators=300, min_samples_split=6, min_samples_leaf=1, max_features='sqrt', max_depth=20)),\n",
    "    ('gb', GradientBoostingRegressor(subsample=1.0, n_estimators=300, max_depth=5, learning_rate=0.1))\n",
    "]\n",
    "stack_reg = StackingRegressor(estimators=estimators, final_estimator=Ridge(alpha=1000.0))\n",
    "stack_reg.fit(X_train_poly, y_train)\n",
    "stack_predictions = stack_reg.predict(X_test_poly)\n",
    "stack_rmse = np.sqrt(mean_squared_error(y_test, stack_predictions))\n",
    "print(f\"Stacking RMSE: {stack_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d920ccb-89ff-430b-8222-809abb965a37",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated RMSE: 0.8704581764037169\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(stack_reg, X_train_poly, y_train, scoring='neg_mean_squared_error', cv=5)\n",
    "cv_rmse = np.sqrt(-scores.mean())\n",
    "print(f\"Cross-Validated RMSE: {cv_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c058b017-501c-46ad-82b6-54f7155ba214",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE after RFE: 0.8727656117086091\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Assuming rf_best is your best RandomForest model\n",
    "selector = RFE(rf_best, n_features_to_select=5, step=1)\n",
    "selector = selector.fit(X_train, y_train)\n",
    "X_train_rfe = selector.transform(X_train)\n",
    "X_test_rfe = selector.transform(X_test)\n",
    "\n",
    "rf_best.fit(X_train_rfe, y_train)\n",
    "predictions_rfe = rf_best.predict(X_test_rfe)\n",
    "rmse_rfe = np.sqrt(mean_squared_error(y_test, predictions_rfe))\n",
    "print(f\"RMSE after RFE: {rmse_rfe}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0fdbd80-c208-4a8b-a805-930108ca4992",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Obtaining dependency information for xgboost from https://files.pythonhosted.org/packages/bc/43/242432efc3f60052a4a534dc4926b21e236ab4ec8d4920c593da3f65c65d/xgboost-2.0.2-py3-none-win_amd64.whl.metadata\n",
      "  Downloading xgboost-2.0.2-py3-none-win_amd64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from xgboost) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from xgboost) (1.11.3)\n",
      "Downloading xgboost-2.0.2-py3-none-win_amd64.whl (99.8 MB)\n",
      "   ---------------------------------------- 0.0/99.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/99.8 MB 1.4 MB/s eta 0:01:14\n",
      "   ---------------------------------------- 0.4/99.8 MB 6.6 MB/s eta 0:00:16\n",
      "   - -------------------------------------- 4.0/99.8 MB 31.7 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 9.5/99.8 MB 55.2 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 14.9/99.8 MB 110.0 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 20.6/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 26.2/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 31.9/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 37.5/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 43.1/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 48.4/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 53.6/99.8 MB 93.9 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 59.1/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 64.8/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 70.3/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 76.0/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 80.5/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 86.1/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 91.6/99.8 MB 129.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.2/99.8 MB 131.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/99.8 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 99.8/99.8 MB 46.7 MB/s eta 0:00:00\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.0.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "71761133-2932-486c-a4eb-e5b0ef2ca702",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Obtaining dependency information for catboost from https://files.pythonhosted.org/packages/e2/63/379617e3d982e8a66c9d66ebf4621d3357c7c18ad356473c335bffd5aba6/catboost-1.2.2-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading catboost-1.2.2-cp311-cp311-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
      "     ---------------------------------------- 0.0/47.0 kB ? eta -:--:--\n",
      "     --------------------------------- ---- 41.0/47.0 kB 653.6 kB/s eta 0:00:01\n",
      "     -------------------------------------- 47.0/47.0 kB 782.9 kB/s eta 0:00:00\n",
      "Requirement already satisfied: matplotlib in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (3.8.0)\n",
      "Requirement already satisfied: numpy>=1.16.0 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (1.24.3)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (2.1.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (1.11.3)\n",
      "Requirement already satisfied: plotly in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from pandas>=0.24->catboost) (2023.3)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (23.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (10.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from matplotlib->catboost) (3.0.9)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\yatish\\anaconda3\\lib\\site-packages (from plotly->catboost) (8.2.2)\n",
      "Downloading catboost-1.2.2-cp311-cp311-win_amd64.whl (101.0 MB)\n",
      "   ---------------------------------------- 0.0/101.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.2/101.0 MB 7.3 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 2.6/101.0 MB 27.6 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 7.3/101.0 MB 51.9 MB/s eta 0:00:02\n",
      "   ---- ---------------------------------- 12.2/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ------ -------------------------------- 17.9/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------- ----------------------------- 23.5/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------- --------------------------- 29.2/101.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------- ------------------------- 34.8/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   -------------- ------------------------ 37.7/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 43.5/101.0 MB 93.9 MB/s eta 0:00:01\n",
      "   ------------------ -------------------- 49.1/101.0 MB 131.2 MB/s eta 0:00:01\n",
      "   --------------------- ----------------- 54.5/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ----------------------- --------------- 60.2/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------- ------------- 65.8/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------- ----------- 71.4/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   ----------------------------- --------- 77.1/101.0 MB 131.2 MB/s eta 0:00:01\n",
      "   ------------------------------- ------- 82.7/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 88.3/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 94.0/101.0 MB 108.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  99.5/101.0 MB 131.2 MB/s eta 0:00:01\n",
      "   -------------------------------------  101.0/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  101.0/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  101.0/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  101.0/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   -------------------------------------  101.0/101.0 MB 110.0 MB/s eta 0:00:01\n",
      "   --------------------------------------- 101.0/101.0 MB 31.2 MB/s eta 0:00:00\n",
      "Installing collected packages: graphviz, catboost\n",
      "Successfully installed catboost-1.2.2 graphviz-0.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eba45e55-1575-44a2-9884-57b36056fbbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost - Best Params: {'n_estimators': 300, 'max_depth': 5, 'learning_rate': 0.1}, RMSE: 0.8771406367450417\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_model = XGBRegressor()\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "xgb_search = RandomizedSearchCV(xgb_model, xgb_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "xgb_search.fit(X_train, y_train)\n",
    "xgb_best = xgb_search.best_estimator_\n",
    "xgb_predictions = xgb_best.predict(X_test)\n",
    "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_predictions))\n",
    "print(f\"XGBoost - Best Params: {xgb_search.best_params_}, RMSE: {xgb_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71e66265-77c0-4736-9bf7-b10e7175b6dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 1.0152617\ttotal: 180ms\tremaining: 53.9s\n",
      "1:\tlearn: 0.9861950\ttotal: 214ms\tremaining: 31.9s\n",
      "2:\tlearn: 0.9662492\ttotal: 245ms\tremaining: 24.3s\n",
      "3:\tlearn: 0.9521952\ttotal: 277ms\tremaining: 20.5s\n",
      "4:\tlearn: 0.9418248\ttotal: 310ms\tremaining: 18.3s\n",
      "5:\tlearn: 0.9313649\ttotal: 342ms\tremaining: 16.8s\n",
      "6:\tlearn: 0.9238614\ttotal: 374ms\tremaining: 15.7s\n",
      "7:\tlearn: 0.9182535\ttotal: 408ms\tremaining: 14.9s\n",
      "8:\tlearn: 0.9136505\ttotal: 442ms\tremaining: 14.3s\n",
      "9:\tlearn: 0.9098384\ttotal: 474ms\tremaining: 13.8s\n",
      "10:\tlearn: 0.9071500\ttotal: 506ms\tremaining: 13.3s\n",
      "11:\tlearn: 0.9044216\ttotal: 541ms\tremaining: 13s\n",
      "12:\tlearn: 0.9024653\ttotal: 575ms\tremaining: 12.7s\n",
      "13:\tlearn: 0.9010250\ttotal: 610ms\tremaining: 12.5s\n",
      "14:\tlearn: 0.8993137\ttotal: 645ms\tremaining: 12.3s\n",
      "15:\tlearn: 0.8977772\ttotal: 680ms\tremaining: 12.1s\n",
      "16:\tlearn: 0.8966459\ttotal: 712ms\tremaining: 11.9s\n",
      "17:\tlearn: 0.8956482\ttotal: 745ms\tremaining: 11.7s\n",
      "18:\tlearn: 0.8947469\ttotal: 777ms\tremaining: 11.5s\n",
      "19:\tlearn: 0.8938529\ttotal: 812ms\tremaining: 11.4s\n",
      "20:\tlearn: 0.8932834\ttotal: 845ms\tremaining: 11.2s\n",
      "21:\tlearn: 0.8925320\ttotal: 883ms\tremaining: 11.2s\n",
      "22:\tlearn: 0.8915324\ttotal: 917ms\tremaining: 11s\n",
      "23:\tlearn: 0.8910769\ttotal: 947ms\tremaining: 10.9s\n",
      "24:\tlearn: 0.8906403\ttotal: 977ms\tremaining: 10.8s\n",
      "25:\tlearn: 0.8899003\ttotal: 1.01s\tremaining: 10.6s\n",
      "26:\tlearn: 0.8893335\ttotal: 1.04s\tremaining: 10.5s\n",
      "27:\tlearn: 0.8890171\ttotal: 1.07s\tremaining: 10.4s\n",
      "28:\tlearn: 0.8884472\ttotal: 1.1s\tremaining: 10.3s\n",
      "29:\tlearn: 0.8880336\ttotal: 1.13s\tremaining: 10.2s\n",
      "30:\tlearn: 0.8877836\ttotal: 1.16s\tremaining: 10.1s\n",
      "31:\tlearn: 0.8875113\ttotal: 1.19s\tremaining: 10s\n",
      "32:\tlearn: 0.8870813\ttotal: 1.23s\tremaining: 9.92s\n",
      "33:\tlearn: 0.8867859\ttotal: 1.26s\tremaining: 9.84s\n",
      "34:\tlearn: 0.8866140\ttotal: 1.29s\tremaining: 9.75s\n",
      "35:\tlearn: 0.8862915\ttotal: 1.32s\tremaining: 9.68s\n",
      "36:\tlearn: 0.8859557\ttotal: 1.35s\tremaining: 9.61s\n",
      "37:\tlearn: 0.8857386\ttotal: 1.38s\tremaining: 9.54s\n",
      "38:\tlearn: 0.8855066\ttotal: 1.42s\tremaining: 9.48s\n",
      "39:\tlearn: 0.8852348\ttotal: 1.45s\tremaining: 9.42s\n",
      "40:\tlearn: 0.8850039\ttotal: 1.48s\tremaining: 9.36s\n",
      "41:\tlearn: 0.8847943\ttotal: 1.51s\tremaining: 9.29s\n",
      "42:\tlearn: 0.8846030\ttotal: 1.54s\tremaining: 9.24s\n",
      "43:\tlearn: 0.8843868\ttotal: 1.58s\tremaining: 9.18s\n",
      "44:\tlearn: 0.8841902\ttotal: 1.61s\tremaining: 9.12s\n",
      "45:\tlearn: 0.8839370\ttotal: 1.64s\tremaining: 9.06s\n",
      "46:\tlearn: 0.8838073\ttotal: 1.67s\tremaining: 8.99s\n",
      "47:\tlearn: 0.8836617\ttotal: 1.7s\tremaining: 8.94s\n",
      "48:\tlearn: 0.8835822\ttotal: 1.73s\tremaining: 8.88s\n",
      "49:\tlearn: 0.8834214\ttotal: 1.76s\tremaining: 8.81s\n",
      "50:\tlearn: 0.8832635\ttotal: 1.8s\tremaining: 8.77s\n",
      "51:\tlearn: 0.8830865\ttotal: 1.83s\tremaining: 8.72s\n",
      "52:\tlearn: 0.8829833\ttotal: 1.86s\tremaining: 8.68s\n",
      "53:\tlearn: 0.8827994\ttotal: 1.89s\tremaining: 8.63s\n",
      "54:\tlearn: 0.8827051\ttotal: 1.92s\tremaining: 8.56s\n",
      "55:\tlearn: 0.8825713\ttotal: 1.95s\tremaining: 8.51s\n",
      "56:\tlearn: 0.8824318\ttotal: 1.98s\tremaining: 8.46s\n",
      "57:\tlearn: 0.8823179\ttotal: 2.02s\tremaining: 8.41s\n",
      "58:\tlearn: 0.8822251\ttotal: 2.05s\tremaining: 8.36s\n",
      "59:\tlearn: 0.8821029\ttotal: 2.08s\tremaining: 8.31s\n",
      "60:\tlearn: 0.8819837\ttotal: 2.11s\tremaining: 8.27s\n",
      "61:\tlearn: 0.8818506\ttotal: 2.14s\tremaining: 8.22s\n",
      "62:\tlearn: 0.8817343\ttotal: 2.18s\tremaining: 8.19s\n",
      "63:\tlearn: 0.8816150\ttotal: 2.21s\tremaining: 8.16s\n",
      "64:\tlearn: 0.8815519\ttotal: 2.25s\tremaining: 8.12s\n",
      "65:\tlearn: 0.8814410\ttotal: 2.28s\tremaining: 8.08s\n",
      "66:\tlearn: 0.8813769\ttotal: 2.31s\tremaining: 8.02s\n",
      "67:\tlearn: 0.8812592\ttotal: 2.33s\tremaining: 7.97s\n",
      "68:\tlearn: 0.8811299\ttotal: 2.37s\tremaining: 7.92s\n",
      "69:\tlearn: 0.8810267\ttotal: 2.39s\tremaining: 7.87s\n",
      "70:\tlearn: 0.8809667\ttotal: 2.42s\tremaining: 7.82s\n",
      "71:\tlearn: 0.8808617\ttotal: 2.46s\tremaining: 7.78s\n",
      "72:\tlearn: 0.8807167\ttotal: 2.49s\tremaining: 7.74s\n",
      "73:\tlearn: 0.8806313\ttotal: 2.52s\tremaining: 7.7s\n",
      "74:\tlearn: 0.8805367\ttotal: 2.55s\tremaining: 7.65s\n",
      "75:\tlearn: 0.8804539\ttotal: 2.58s\tremaining: 7.61s\n",
      "76:\tlearn: 0.8803541\ttotal: 2.61s\tremaining: 7.57s\n",
      "77:\tlearn: 0.8803080\ttotal: 2.65s\tremaining: 7.54s\n",
      "78:\tlearn: 0.8802178\ttotal: 2.68s\tremaining: 7.49s\n",
      "79:\tlearn: 0.8801514\ttotal: 2.71s\tremaining: 7.45s\n",
      "80:\tlearn: 0.8800678\ttotal: 2.74s\tremaining: 7.41s\n",
      "81:\tlearn: 0.8799880\ttotal: 2.77s\tremaining: 7.37s\n",
      "82:\tlearn: 0.8799321\ttotal: 2.8s\tremaining: 7.33s\n",
      "83:\tlearn: 0.8798482\ttotal: 2.84s\tremaining: 7.29s\n",
      "84:\tlearn: 0.8797804\ttotal: 2.87s\tremaining: 7.26s\n",
      "85:\tlearn: 0.8797275\ttotal: 2.9s\tremaining: 7.22s\n",
      "86:\tlearn: 0.8796723\ttotal: 2.93s\tremaining: 7.17s\n",
      "87:\tlearn: 0.8796202\ttotal: 2.96s\tremaining: 7.13s\n",
      "88:\tlearn: 0.8795271\ttotal: 2.99s\tremaining: 7.1s\n",
      "89:\tlearn: 0.8794236\ttotal: 3.02s\tremaining: 7.06s\n",
      "90:\tlearn: 0.8793744\ttotal: 3.06s\tremaining: 7.02s\n",
      "91:\tlearn: 0.8793034\ttotal: 3.09s\tremaining: 6.98s\n",
      "92:\tlearn: 0.8792364\ttotal: 3.12s\tremaining: 6.95s\n",
      "93:\tlearn: 0.8791832\ttotal: 3.15s\tremaining: 6.91s\n",
      "94:\tlearn: 0.8791437\ttotal: 3.18s\tremaining: 6.87s\n",
      "95:\tlearn: 0.8790711\ttotal: 3.21s\tremaining: 6.83s\n",
      "96:\tlearn: 0.8790067\ttotal: 3.24s\tremaining: 6.78s\n",
      "97:\tlearn: 0.8789209\ttotal: 3.27s\tremaining: 6.75s\n",
      "98:\tlearn: 0.8788633\ttotal: 3.3s\tremaining: 6.71s\n",
      "99:\tlearn: 0.8787957\ttotal: 3.33s\tremaining: 6.67s\n",
      "100:\tlearn: 0.8787614\ttotal: 3.37s\tremaining: 6.63s\n",
      "101:\tlearn: 0.8787105\ttotal: 3.4s\tremaining: 6.59s\n",
      "102:\tlearn: 0.8786532\ttotal: 3.43s\tremaining: 6.56s\n",
      "103:\tlearn: 0.8786098\ttotal: 3.46s\tremaining: 6.52s\n",
      "104:\tlearn: 0.8785500\ttotal: 3.49s\tremaining: 6.49s\n",
      "105:\tlearn: 0.8784970\ttotal: 3.52s\tremaining: 6.45s\n",
      "106:\tlearn: 0.8784475\ttotal: 3.56s\tremaining: 6.41s\n",
      "107:\tlearn: 0.8783805\ttotal: 3.58s\tremaining: 6.37s\n",
      "108:\tlearn: 0.8782974\ttotal: 3.62s\tremaining: 6.34s\n",
      "109:\tlearn: 0.8782736\ttotal: 3.65s\tremaining: 6.3s\n",
      "110:\tlearn: 0.8781978\ttotal: 3.68s\tremaining: 6.26s\n",
      "111:\tlearn: 0.8781695\ttotal: 3.71s\tremaining: 6.22s\n",
      "112:\tlearn: 0.8781044\ttotal: 3.74s\tremaining: 6.19s\n",
      "113:\tlearn: 0.8780650\ttotal: 3.78s\tremaining: 6.16s\n",
      "114:\tlearn: 0.8780121\ttotal: 3.81s\tremaining: 6.13s\n",
      "115:\tlearn: 0.8779307\ttotal: 3.84s\tremaining: 6.09s\n",
      "116:\tlearn: 0.8778856\ttotal: 3.87s\tremaining: 6.06s\n",
      "117:\tlearn: 0.8778458\ttotal: 3.9s\tremaining: 6.02s\n",
      "118:\tlearn: 0.8777939\ttotal: 3.93s\tremaining: 5.98s\n",
      "119:\tlearn: 0.8777613\ttotal: 3.96s\tremaining: 5.94s\n",
      "120:\tlearn: 0.8777147\ttotal: 3.99s\tremaining: 5.91s\n",
      "121:\tlearn: 0.8776623\ttotal: 4.03s\tremaining: 5.88s\n",
      "122:\tlearn: 0.8776079\ttotal: 4.06s\tremaining: 5.84s\n",
      "123:\tlearn: 0.8775818\ttotal: 4.09s\tremaining: 5.81s\n",
      "124:\tlearn: 0.8775338\ttotal: 4.12s\tremaining: 5.77s\n",
      "125:\tlearn: 0.8774869\ttotal: 4.16s\tremaining: 5.74s\n",
      "126:\tlearn: 0.8774336\ttotal: 4.19s\tremaining: 5.71s\n",
      "127:\tlearn: 0.8773910\ttotal: 4.22s\tremaining: 5.67s\n",
      "128:\tlearn: 0.8773364\ttotal: 4.25s\tremaining: 5.64s\n",
      "129:\tlearn: 0.8772888\ttotal: 4.28s\tremaining: 5.6s\n",
      "130:\tlearn: 0.8772527\ttotal: 4.32s\tremaining: 5.57s\n",
      "131:\tlearn: 0.8772171\ttotal: 4.35s\tremaining: 5.53s\n",
      "132:\tlearn: 0.8771865\ttotal: 4.38s\tremaining: 5.5s\n",
      "133:\tlearn: 0.8771400\ttotal: 4.41s\tremaining: 5.47s\n",
      "134:\tlearn: 0.8771106\ttotal: 4.45s\tremaining: 5.44s\n",
      "135:\tlearn: 0.8770882\ttotal: 4.48s\tremaining: 5.4s\n",
      "136:\tlearn: 0.8770598\ttotal: 4.51s\tremaining: 5.37s\n",
      "137:\tlearn: 0.8770034\ttotal: 4.54s\tremaining: 5.33s\n",
      "138:\tlearn: 0.8769770\ttotal: 4.58s\tremaining: 5.3s\n",
      "139:\tlearn: 0.8769421\ttotal: 4.61s\tremaining: 5.26s\n",
      "140:\tlearn: 0.8769208\ttotal: 4.64s\tremaining: 5.23s\n",
      "141:\tlearn: 0.8768999\ttotal: 4.67s\tremaining: 5.2s\n",
      "142:\tlearn: 0.8768404\ttotal: 4.7s\tremaining: 5.16s\n",
      "143:\tlearn: 0.8767580\ttotal: 4.73s\tremaining: 5.13s\n",
      "144:\tlearn: 0.8767202\ttotal: 4.76s\tremaining: 5.09s\n",
      "145:\tlearn: 0.8766895\ttotal: 4.8s\tremaining: 5.06s\n",
      "146:\tlearn: 0.8766526\ttotal: 4.83s\tremaining: 5.03s\n",
      "147:\tlearn: 0.8766181\ttotal: 4.86s\tremaining: 4.99s\n",
      "148:\tlearn: 0.8765820\ttotal: 4.89s\tremaining: 4.96s\n",
      "149:\tlearn: 0.8765501\ttotal: 4.92s\tremaining: 4.92s\n",
      "150:\tlearn: 0.8765204\ttotal: 4.95s\tremaining: 4.88s\n",
      "151:\tlearn: 0.8764715\ttotal: 4.98s\tremaining: 4.85s\n",
      "152:\tlearn: 0.8764338\ttotal: 5.01s\tremaining: 4.81s\n",
      "153:\tlearn: 0.8763987\ttotal: 5.04s\tremaining: 4.78s\n",
      "154:\tlearn: 0.8763786\ttotal: 5.08s\tremaining: 4.75s\n",
      "155:\tlearn: 0.8763486\ttotal: 5.11s\tremaining: 4.71s\n",
      "156:\tlearn: 0.8763154\ttotal: 5.14s\tremaining: 4.68s\n",
      "157:\tlearn: 0.8762864\ttotal: 5.17s\tremaining: 4.64s\n",
      "158:\tlearn: 0.8762444\ttotal: 5.2s\tremaining: 4.61s\n",
      "159:\tlearn: 0.8762147\ttotal: 5.23s\tremaining: 4.58s\n",
      "160:\tlearn: 0.8762027\ttotal: 5.26s\tremaining: 4.54s\n",
      "161:\tlearn: 0.8761798\ttotal: 5.29s\tremaining: 4.51s\n",
      "162:\tlearn: 0.8761540\ttotal: 5.33s\tremaining: 4.48s\n",
      "163:\tlearn: 0.8761099\ttotal: 5.36s\tremaining: 4.44s\n",
      "164:\tlearn: 0.8760802\ttotal: 5.39s\tremaining: 4.41s\n",
      "165:\tlearn: 0.8760498\ttotal: 5.42s\tremaining: 4.38s\n",
      "166:\tlearn: 0.8760290\ttotal: 5.45s\tremaining: 4.34s\n",
      "167:\tlearn: 0.8759903\ttotal: 5.48s\tremaining: 4.3s\n",
      "168:\tlearn: 0.8759524\ttotal: 5.51s\tremaining: 4.27s\n",
      "169:\tlearn: 0.8759287\ttotal: 5.55s\tremaining: 4.24s\n",
      "170:\tlearn: 0.8759054\ttotal: 5.58s\tremaining: 4.21s\n",
      "171:\tlearn: 0.8758698\ttotal: 5.61s\tremaining: 4.18s\n",
      "172:\tlearn: 0.8758330\ttotal: 5.64s\tremaining: 4.14s\n",
      "173:\tlearn: 0.8758013\ttotal: 5.67s\tremaining: 4.11s\n",
      "174:\tlearn: 0.8757757\ttotal: 5.71s\tremaining: 4.08s\n",
      "175:\tlearn: 0.8757519\ttotal: 5.73s\tremaining: 4.04s\n",
      "176:\tlearn: 0.8757403\ttotal: 5.76s\tremaining: 4.01s\n",
      "177:\tlearn: 0.8756790\ttotal: 5.8s\tremaining: 3.97s\n",
      "178:\tlearn: 0.8756508\ttotal: 5.83s\tremaining: 3.94s\n",
      "179:\tlearn: 0.8756259\ttotal: 5.86s\tremaining: 3.91s\n",
      "180:\tlearn: 0.8756024\ttotal: 5.89s\tremaining: 3.88s\n",
      "181:\tlearn: 0.8755850\ttotal: 5.93s\tremaining: 3.84s\n",
      "182:\tlearn: 0.8755653\ttotal: 5.96s\tremaining: 3.81s\n",
      "183:\tlearn: 0.8755488\ttotal: 5.99s\tremaining: 3.78s\n",
      "184:\tlearn: 0.8755350\ttotal: 6.02s\tremaining: 3.74s\n",
      "185:\tlearn: 0.8754967\ttotal: 6.05s\tremaining: 3.71s\n",
      "186:\tlearn: 0.8754732\ttotal: 6.09s\tremaining: 3.68s\n",
      "187:\tlearn: 0.8754580\ttotal: 6.12s\tremaining: 3.65s\n",
      "188:\tlearn: 0.8754305\ttotal: 6.15s\tremaining: 3.61s\n",
      "189:\tlearn: 0.8754003\ttotal: 6.19s\tremaining: 3.58s\n",
      "190:\tlearn: 0.8753783\ttotal: 6.22s\tremaining: 3.55s\n",
      "191:\tlearn: 0.8753314\ttotal: 6.25s\tremaining: 3.52s\n",
      "192:\tlearn: 0.8753109\ttotal: 6.28s\tremaining: 3.48s\n",
      "193:\tlearn: 0.8752901\ttotal: 6.32s\tremaining: 3.45s\n",
      "194:\tlearn: 0.8752540\ttotal: 6.35s\tremaining: 3.42s\n",
      "195:\tlearn: 0.8752187\ttotal: 6.38s\tremaining: 3.38s\n",
      "196:\tlearn: 0.8752000\ttotal: 6.41s\tremaining: 3.35s\n",
      "197:\tlearn: 0.8751852\ttotal: 6.44s\tremaining: 3.32s\n",
      "198:\tlearn: 0.8751752\ttotal: 6.47s\tremaining: 3.28s\n",
      "199:\tlearn: 0.8751466\ttotal: 6.5s\tremaining: 3.25s\n",
      "200:\tlearn: 0.8751121\ttotal: 6.54s\tremaining: 3.22s\n",
      "201:\tlearn: 0.8750849\ttotal: 6.57s\tremaining: 3.19s\n",
      "202:\tlearn: 0.8750684\ttotal: 6.6s\tremaining: 3.15s\n",
      "203:\tlearn: 0.8750371\ttotal: 6.63s\tremaining: 3.12s\n",
      "204:\tlearn: 0.8750146\ttotal: 6.66s\tremaining: 3.09s\n",
      "205:\tlearn: 0.8750056\ttotal: 6.69s\tremaining: 3.05s\n",
      "206:\tlearn: 0.8749864\ttotal: 6.72s\tremaining: 3.02s\n",
      "207:\tlearn: 0.8749597\ttotal: 6.76s\tremaining: 2.99s\n",
      "208:\tlearn: 0.8749366\ttotal: 6.79s\tremaining: 2.96s\n",
      "209:\tlearn: 0.8749181\ttotal: 6.82s\tremaining: 2.92s\n",
      "210:\tlearn: 0.8749071\ttotal: 6.85s\tremaining: 2.89s\n",
      "211:\tlearn: 0.8748913\ttotal: 6.88s\tremaining: 2.86s\n",
      "212:\tlearn: 0.8748683\ttotal: 6.91s\tremaining: 2.82s\n",
      "213:\tlearn: 0.8748487\ttotal: 6.95s\tremaining: 2.79s\n",
      "214:\tlearn: 0.8748321\ttotal: 6.98s\tremaining: 2.76s\n",
      "215:\tlearn: 0.8748155\ttotal: 7.01s\tremaining: 2.73s\n",
      "216:\tlearn: 0.8747995\ttotal: 7.04s\tremaining: 2.69s\n",
      "217:\tlearn: 0.8747823\ttotal: 7.07s\tremaining: 2.66s\n",
      "218:\tlearn: 0.8747612\ttotal: 7.11s\tremaining: 2.63s\n",
      "219:\tlearn: 0.8747471\ttotal: 7.14s\tremaining: 2.6s\n",
      "220:\tlearn: 0.8747367\ttotal: 7.17s\tremaining: 2.56s\n",
      "221:\tlearn: 0.8747106\ttotal: 7.2s\tremaining: 2.53s\n",
      "222:\tlearn: 0.8746965\ttotal: 7.23s\tremaining: 2.5s\n",
      "223:\tlearn: 0.8746815\ttotal: 7.26s\tremaining: 2.46s\n",
      "224:\tlearn: 0.8746655\ttotal: 7.3s\tremaining: 2.43s\n",
      "225:\tlearn: 0.8746420\ttotal: 7.33s\tremaining: 2.4s\n",
      "226:\tlearn: 0.8746283\ttotal: 7.36s\tremaining: 2.37s\n",
      "227:\tlearn: 0.8746118\ttotal: 7.39s\tremaining: 2.33s\n",
      "228:\tlearn: 0.8745898\ttotal: 7.42s\tremaining: 2.3s\n",
      "229:\tlearn: 0.8745611\ttotal: 7.45s\tremaining: 2.27s\n",
      "230:\tlearn: 0.8745453\ttotal: 7.48s\tremaining: 2.23s\n",
      "231:\tlearn: 0.8745321\ttotal: 7.51s\tremaining: 2.2s\n",
      "232:\tlearn: 0.8745098\ttotal: 7.54s\tremaining: 2.17s\n",
      "233:\tlearn: 0.8745046\ttotal: 7.58s\tremaining: 2.14s\n",
      "234:\tlearn: 0.8744858\ttotal: 7.61s\tremaining: 2.1s\n",
      "235:\tlearn: 0.8744776\ttotal: 7.64s\tremaining: 2.07s\n",
      "236:\tlearn: 0.8744552\ttotal: 7.67s\tremaining: 2.04s\n",
      "237:\tlearn: 0.8744431\ttotal: 7.7s\tremaining: 2s\n",
      "238:\tlearn: 0.8744300\ttotal: 7.73s\tremaining: 1.97s\n",
      "239:\tlearn: 0.8744170\ttotal: 7.76s\tremaining: 1.94s\n",
      "240:\tlearn: 0.8744068\ttotal: 7.79s\tremaining: 1.91s\n",
      "241:\tlearn: 0.8743795\ttotal: 7.83s\tremaining: 1.88s\n",
      "242:\tlearn: 0.8743579\ttotal: 7.86s\tremaining: 1.84s\n",
      "243:\tlearn: 0.8743401\ttotal: 7.89s\tremaining: 1.81s\n",
      "244:\tlearn: 0.8743278\ttotal: 7.93s\tremaining: 1.78s\n",
      "245:\tlearn: 0.8743169\ttotal: 7.96s\tremaining: 1.75s\n",
      "246:\tlearn: 0.8743008\ttotal: 7.99s\tremaining: 1.71s\n",
      "247:\tlearn: 0.8742873\ttotal: 8.02s\tremaining: 1.68s\n",
      "248:\tlearn: 0.8742748\ttotal: 8.05s\tremaining: 1.65s\n",
      "249:\tlearn: 0.8742632\ttotal: 8.08s\tremaining: 1.62s\n",
      "250:\tlearn: 0.8742505\ttotal: 8.12s\tremaining: 1.58s\n",
      "251:\tlearn: 0.8742376\ttotal: 8.15s\tremaining: 1.55s\n",
      "252:\tlearn: 0.8742164\ttotal: 8.18s\tremaining: 1.52s\n",
      "253:\tlearn: 0.8742042\ttotal: 8.21s\tremaining: 1.49s\n",
      "254:\tlearn: 0.8741866\ttotal: 8.24s\tremaining: 1.45s\n",
      "255:\tlearn: 0.8741748\ttotal: 8.28s\tremaining: 1.42s\n",
      "256:\tlearn: 0.8741584\ttotal: 8.31s\tremaining: 1.39s\n",
      "257:\tlearn: 0.8741460\ttotal: 8.34s\tremaining: 1.36s\n",
      "258:\tlearn: 0.8741333\ttotal: 8.37s\tremaining: 1.32s\n",
      "259:\tlearn: 0.8741064\ttotal: 8.4s\tremaining: 1.29s\n",
      "260:\tlearn: 0.8740880\ttotal: 8.43s\tremaining: 1.26s\n",
      "261:\tlearn: 0.8740791\ttotal: 8.46s\tremaining: 1.23s\n",
      "262:\tlearn: 0.8740737\ttotal: 8.49s\tremaining: 1.19s\n",
      "263:\tlearn: 0.8740612\ttotal: 8.53s\tremaining: 1.16s\n",
      "264:\tlearn: 0.8740528\ttotal: 8.56s\tremaining: 1.13s\n",
      "265:\tlearn: 0.8740473\ttotal: 8.59s\tremaining: 1.1s\n",
      "266:\tlearn: 0.8740353\ttotal: 8.62s\tremaining: 1.06s\n",
      "267:\tlearn: 0.8740208\ttotal: 8.65s\tremaining: 1.03s\n",
      "268:\tlearn: 0.8739984\ttotal: 8.68s\tremaining: 1s\n",
      "269:\tlearn: 0.8739884\ttotal: 8.71s\tremaining: 968ms\n",
      "270:\tlearn: 0.8739779\ttotal: 8.74s\tremaining: 936ms\n",
      "271:\tlearn: 0.8739735\ttotal: 8.78s\tremaining: 903ms\n",
      "272:\tlearn: 0.8739593\ttotal: 8.81s\tremaining: 871ms\n",
      "273:\tlearn: 0.8739447\ttotal: 8.84s\tremaining: 839ms\n",
      "274:\tlearn: 0.8739265\ttotal: 8.87s\tremaining: 807ms\n",
      "275:\tlearn: 0.8739116\ttotal: 8.91s\tremaining: 774ms\n",
      "276:\tlearn: 0.8739006\ttotal: 8.94s\tremaining: 742ms\n",
      "277:\tlearn: 0.8738796\ttotal: 8.97s\tremaining: 710ms\n",
      "278:\tlearn: 0.8738739\ttotal: 9s\tremaining: 678ms\n",
      "279:\tlearn: 0.8738594\ttotal: 9.04s\tremaining: 645ms\n",
      "280:\tlearn: 0.8738426\ttotal: 9.07s\tremaining: 613ms\n",
      "281:\tlearn: 0.8738306\ttotal: 9.1s\tremaining: 581ms\n",
      "282:\tlearn: 0.8738241\ttotal: 9.13s\tremaining: 548ms\n",
      "283:\tlearn: 0.8738132\ttotal: 9.16s\tremaining: 516ms\n",
      "284:\tlearn: 0.8737986\ttotal: 9.2s\tremaining: 484ms\n",
      "285:\tlearn: 0.8737933\ttotal: 9.22s\tremaining: 452ms\n",
      "286:\tlearn: 0.8737811\ttotal: 9.26s\tremaining: 419ms\n",
      "287:\tlearn: 0.8737721\ttotal: 9.29s\tremaining: 387ms\n",
      "288:\tlearn: 0.8737659\ttotal: 9.32s\tremaining: 355ms\n",
      "289:\tlearn: 0.8737587\ttotal: 9.35s\tremaining: 323ms\n",
      "290:\tlearn: 0.8737403\ttotal: 9.39s\tremaining: 290ms\n",
      "291:\tlearn: 0.8737164\ttotal: 9.42s\tremaining: 258ms\n",
      "292:\tlearn: 0.8737011\ttotal: 9.45s\tremaining: 226ms\n",
      "293:\tlearn: 0.8736969\ttotal: 9.48s\tremaining: 193ms\n",
      "294:\tlearn: 0.8736863\ttotal: 9.51s\tremaining: 161ms\n",
      "295:\tlearn: 0.8736663\ttotal: 9.54s\tremaining: 129ms\n",
      "296:\tlearn: 0.8736616\ttotal: 9.57s\tremaining: 96.7ms\n",
      "297:\tlearn: 0.8736509\ttotal: 9.61s\tremaining: 64.5ms\n",
      "298:\tlearn: 0.8736423\ttotal: 9.64s\tremaining: 32.2ms\n",
      "299:\tlearn: 0.8736235\ttotal: 9.67s\tremaining: 0us\n",
      "CatBoost - Best Params: {'learning_rate': 0.2, 'iterations': 300, 'depth': 6}, RMSE: 0.8767969173438941\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostRegressor\n",
    "\n",
    "cat_model = CatBoostRegressor()\n",
    "cat_params = {\n",
    "    'iterations': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'depth': [4, 6, 8]\n",
    "}\n",
    "cat_search = RandomizedSearchCV(cat_model, cat_params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "cat_search.fit(X_train, y_train)\n",
    "cat_best = cat_search.best_estimator_\n",
    "cat_predictions = cat_best.predict(X_test)\n",
    "cat_rmse = np.sqrt(mean_squared_error(y_test, cat_predictions))\n",
    "print(f\"CatBoost - Best Params: {cat_search.best_params_}, RMSE: {cat_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "66535702-2b51-4847-a891-5b089a00631f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "51232/51232 - 39s - loss: 0.8914 - val_loss: 0.8439 - 39s/epoch - 761us/step\n",
      "Epoch 2/100\n",
      "51232/51232 - 39s - loss: 0.8401 - val_loss: 0.8178 - 39s/epoch - 767us/step\n",
      "Epoch 3/100\n",
      "51232/51232 - 40s - loss: 0.8287 - val_loss: 0.8208 - 40s/epoch - 772us/step\n",
      "Epoch 4/100\n",
      "51232/51232 - 39s - loss: 0.8236 - val_loss: 0.8083 - 39s/epoch - 760us/step\n",
      "Epoch 5/100\n",
      "51232/51232 - 39s - loss: 0.8194 - val_loss: 0.8109 - 39s/epoch - 756us/step\n",
      "Epoch 6/100\n",
      "51232/51232 - 39s - loss: 0.8177 - val_loss: 0.8155 - 39s/epoch - 767us/step\n",
      "Epoch 7/100\n",
      "51232/51232 - 39s - loss: 0.8166 - val_loss: 0.8129 - 39s/epoch - 764us/step\n",
      "Epoch 8/100\n",
      "51232/51232 - 38s - loss: 0.8146 - val_loss: 0.8235 - 38s/epoch - 746us/step\n",
      "Epoch 9/100\n",
      "51232/51232 - 38s - loss: 0.8130 - val_loss: 0.8194 - 38s/epoch - 744us/step\n",
      "Epoch 10/100\n",
      "51232/51232 - 39s - loss: 0.8119 - val_loss: 0.8214 - 39s/epoch - 763us/step\n",
      "Epoch 11/100\n",
      "51232/51232 - 39s - loss: 0.8110 - val_loss: 0.8038 - 39s/epoch - 770us/step\n",
      "Epoch 12/100\n",
      "51232/51232 - 39s - loss: 0.8106 - val_loss: 0.8096 - 39s/epoch - 762us/step\n",
      "Epoch 13/100\n",
      "51232/51232 - 39s - loss: 0.8102 - val_loss: 0.8402 - 39s/epoch - 763us/step\n",
      "Epoch 14/100\n",
      "51232/51232 - 39s - loss: 0.8106 - val_loss: 0.8236 - 39s/epoch - 764us/step\n",
      "Epoch 15/100\n",
      "51232/51232 - 39s - loss: 0.8103 - val_loss: 0.8203 - 39s/epoch - 761us/step\n",
      "Epoch 16/100\n",
      "51232/51232 - 39s - loss: 0.8097 - val_loss: 0.8392 - 39s/epoch - 766us/step\n",
      "Epoch 17/100\n",
      "51232/51232 - 39s - loss: 0.8088 - val_loss: 0.8231 - 39s/epoch - 770us/step\n",
      "Epoch 18/100\n",
      "51232/51232 - 40s - loss: 0.8091 - val_loss: 0.8149 - 40s/epoch - 777us/step\n",
      "Epoch 19/100\n",
      "51232/51232 - 39s - loss: 0.8083 - val_loss: 0.8233 - 39s/epoch - 770us/step\n",
      "Epoch 20/100\n",
      "51232/51232 - 39s - loss: 0.8086 - val_loss: 0.8224 - 39s/epoch - 763us/step\n",
      "Epoch 21/100\n",
      "51232/51232 - 39s - loss: 0.8079 - val_loss: 0.8102 - 39s/epoch - 766us/step\n",
      "Epoch 22/100\n",
      "51232/51232 - 40s - loss: 0.8079 - val_loss: 0.8099 - 40s/epoch - 778us/step\n",
      "Epoch 23/100\n",
      "51232/51232 - 39s - loss: 0.8072 - val_loss: 0.8429 - 39s/epoch - 765us/step\n",
      "Epoch 24/100\n",
      "51232/51232 - 39s - loss: 0.8075 - val_loss: 0.8187 - 39s/epoch - 765us/step\n",
      "Epoch 25/100\n",
      "51232/51232 - 39s - loss: 0.8064 - val_loss: 0.8264 - 39s/epoch - 766us/step\n",
      "Epoch 26/100\n",
      "51232/51232 - 39s - loss: 0.8065 - val_loss: 0.8111 - 39s/epoch - 766us/step\n",
      "Epoch 27/100\n",
      "51232/51232 - 35s - loss: 0.8060 - val_loss: 0.8132 - 35s/epoch - 687us/step\n",
      "Epoch 28/100\n",
      "51232/51232 - 32s - loss: 0.8060 - val_loss: 0.8256 - 32s/epoch - 617us/step\n",
      "Epoch 29/100\n",
      "51232/51232 - 32s - loss: 0.8061 - val_loss: 0.8270 - 32s/epoch - 619us/step\n",
      "Epoch 30/100\n",
      "51232/51232 - 32s - loss: 0.8060 - val_loss: 0.8196 - 32s/epoch - 620us/step\n",
      "Epoch 31/100\n",
      "51232/51232 - 32s - loss: 0.8051 - val_loss: 0.8162 - 32s/epoch - 618us/step\n",
      "Epoch 32/100\n",
      "51232/51232 - 31s - loss: 0.8056 - val_loss: 0.8255 - 31s/epoch - 615us/step\n",
      "Epoch 33/100\n",
      "51232/51232 - 32s - loss: 0.8060 - val_loss: 0.8180 - 32s/epoch - 615us/step\n",
      "Epoch 34/100\n",
      "51232/51232 - 38s - loss: 0.8053 - val_loss: 0.8150 - 38s/epoch - 740us/step\n",
      "Epoch 35/100\n",
      "51232/51232 - 40s - loss: 0.8056 - val_loss: 0.8155 - 40s/epoch - 788us/step\n",
      "Epoch 36/100\n",
      "51232/51232 - 41s - loss: 0.8053 - val_loss: 0.8173 - 41s/epoch - 797us/step\n",
      "Epoch 37/100\n",
      "51232/51232 - 39s - loss: 0.8047 - val_loss: 0.8247 - 39s/epoch - 766us/step\n",
      "Epoch 38/100\n",
      "51232/51232 - 39s - loss: 0.8050 - val_loss: 0.8303 - 39s/epoch - 759us/step\n",
      "Epoch 39/100\n",
      "51232/51232 - 40s - loss: 0.8048 - val_loss: 0.8187 - 40s/epoch - 777us/step\n",
      "Epoch 40/100\n",
      "51232/51232 - 39s - loss: 0.8050 - val_loss: 0.8091 - 39s/epoch - 758us/step\n",
      "Epoch 41/100\n",
      "51232/51232 - 39s - loss: 0.8049 - val_loss: 0.8048 - 39s/epoch - 752us/step\n",
      "Epoch 42/100\n",
      "51232/51232 - 39s - loss: 0.8048 - val_loss: 0.8012 - 39s/epoch - 764us/step\n",
      "Epoch 43/100\n",
      "51232/51232 - 40s - loss: 0.8046 - val_loss: 0.8228 - 40s/epoch - 779us/step\n",
      "Epoch 44/100\n",
      "51232/51232 - 40s - loss: 0.8044 - val_loss: 0.8053 - 40s/epoch - 789us/step\n",
      "Epoch 45/100\n",
      "51232/51232 - 39s - loss: 0.8053 - val_loss: 0.8155 - 39s/epoch - 766us/step\n",
      "Epoch 46/100\n",
      "51232/51232 - 39s - loss: 0.8046 - val_loss: 0.8178 - 39s/epoch - 765us/step\n",
      "Epoch 47/100\n",
      "51232/51232 - 40s - loss: 0.8051 - val_loss: 0.8224 - 40s/epoch - 788us/step\n",
      "Epoch 48/100\n",
      "51232/51232 - 40s - loss: 0.8045 - val_loss: 0.8294 - 40s/epoch - 790us/step\n",
      "Epoch 49/100\n",
      "51232/51232 - 40s - loss: 0.8048 - val_loss: 0.8097 - 40s/epoch - 783us/step\n",
      "Epoch 50/100\n",
      "51232/51232 - 40s - loss: 0.8037 - val_loss: 0.8188 - 40s/epoch - 787us/step\n",
      "Epoch 51/100\n",
      "51232/51232 - 40s - loss: 0.8038 - val_loss: 0.8092 - 40s/epoch - 786us/step\n",
      "Epoch 52/100\n",
      "51232/51232 - 39s - loss: 0.8037 - val_loss: 0.8446 - 39s/epoch - 771us/step\n",
      "Epoch 53/100\n",
      "51232/51232 - 40s - loss: 0.8038 - val_loss: 0.8198 - 40s/epoch - 780us/step\n",
      "Epoch 54/100\n",
      "51232/51232 - 40s - loss: 0.8038 - val_loss: 0.8164 - 40s/epoch - 786us/step\n",
      "Epoch 55/100\n",
      "51232/51232 - 40s - loss: 0.8037 - val_loss: 0.8158 - 40s/epoch - 772us/step\n",
      "Epoch 56/100\n",
      "51232/51232 - 41s - loss: 0.8032 - val_loss: 0.8200 - 41s/epoch - 792us/step\n",
      "Epoch 57/100\n",
      "51232/51232 - 40s - loss: 0.8034 - val_loss: 0.8244 - 40s/epoch - 773us/step\n",
      "Epoch 58/100\n",
      "51232/51232 - 39s - loss: 0.8038 - val_loss: 0.8219 - 39s/epoch - 755us/step\n",
      "Epoch 59/100\n",
      "51232/51232 - 39s - loss: 0.8034 - val_loss: 0.8130 - 39s/epoch - 770us/step\n",
      "Epoch 60/100\n",
      "51232/51232 - 39s - loss: 0.8036 - val_loss: 0.8203 - 39s/epoch - 770us/step\n",
      "Epoch 61/100\n",
      "51232/51232 - 39s - loss: 0.8038 - val_loss: 0.8265 - 39s/epoch - 765us/step\n",
      "Epoch 62/100\n",
      "51232/51232 - 40s - loss: 0.8038 - val_loss: 0.8206 - 40s/epoch - 786us/step\n",
      "Epoch 63/100\n",
      "51232/51232 - 40s - loss: 0.8038 - val_loss: 0.8268 - 40s/epoch - 778us/step\n",
      "Epoch 64/100\n",
      "51232/51232 - 40s - loss: 0.8040 - val_loss: 0.8188 - 40s/epoch - 776us/step\n",
      "Epoch 65/100\n",
      "51232/51232 - 40s - loss: 0.8036 - val_loss: 0.8082 - 40s/epoch - 790us/step\n",
      "Epoch 66/100\n",
      "51232/51232 - 39s - loss: 0.8036 - val_loss: 0.8113 - 39s/epoch - 766us/step\n",
      "Epoch 67/100\n",
      "51232/51232 - 39s - loss: 0.8045 - val_loss: 0.8160 - 39s/epoch - 758us/step\n",
      "Epoch 68/100\n",
      "51232/51232 - 40s - loss: 0.8039 - val_loss: 0.8153 - 40s/epoch - 778us/step\n",
      "Epoch 69/100\n",
      "51232/51232 - 40s - loss: 0.8040 - val_loss: 0.8217 - 40s/epoch - 779us/step\n",
      "Epoch 70/100\n",
      "51232/51232 - 40s - loss: 0.8043 - val_loss: 0.8402 - 40s/epoch - 774us/step\n",
      "Epoch 71/100\n",
      "51232/51232 - 40s - loss: 0.8037 - val_loss: 0.7984 - 40s/epoch - 786us/step\n",
      "Epoch 72/100\n",
      "51232/51232 - 39s - loss: 0.8043 - val_loss: 0.8216 - 39s/epoch - 761us/step\n",
      "Epoch 73/100\n",
      "51232/51232 - 40s - loss: 0.8034 - val_loss: 0.8095 - 40s/epoch - 779us/step\n",
      "Epoch 74/100\n",
      "51232/51232 - 40s - loss: 0.8039 - val_loss: 0.8255 - 40s/epoch - 780us/step\n",
      "Epoch 75/100\n",
      "51232/51232 - 40s - loss: 0.8032 - val_loss: 0.8155 - 40s/epoch - 771us/step\n",
      "Epoch 76/100\n",
      "51232/51232 - 40s - loss: 0.8037 - val_loss: 0.8169 - 40s/epoch - 779us/step\n",
      "Epoch 77/100\n",
      "51232/51232 - 41s - loss: 0.8032 - val_loss: 0.8291 - 41s/epoch - 792us/step\n",
      "Epoch 78/100\n",
      "51232/51232 - 40s - loss: 0.8034 - val_loss: 0.8330 - 40s/epoch - 787us/step\n",
      "Epoch 79/100\n",
      "51232/51232 - 41s - loss: 0.8033 - val_loss: 0.8104 - 41s/epoch - 793us/step\n",
      "Epoch 80/100\n",
      "51232/51232 - 39s - loss: 0.8029 - val_loss: 0.8122 - 39s/epoch - 754us/step\n",
      "Epoch 81/100\n",
      "51232/51232 - 39s - loss: 0.8025 - val_loss: 0.8197 - 39s/epoch - 765us/step\n",
      "Epoch 82/100\n",
      "51232/51232 - 40s - loss: 0.8031 - val_loss: 0.8178 - 40s/epoch - 788us/step\n",
      "Epoch 83/100\n",
      "51232/51232 - 41s - loss: 0.8036 - val_loss: 0.8280 - 41s/epoch - 807us/step\n",
      "Epoch 84/100\n",
      "51232/51232 - 42s - loss: 0.8039 - val_loss: 0.8144 - 42s/epoch - 829us/step\n",
      "Epoch 85/100\n",
      "51232/51232 - 44s - loss: 0.8030 - val_loss: 0.8271 - 44s/epoch - 859us/step\n",
      "Epoch 86/100\n",
      "51232/51232 - 44s - loss: 0.8027 - val_loss: 0.8022 - 44s/epoch - 850us/step\n",
      "Epoch 87/100\n",
      "51232/51232 - 41s - loss: 0.8031 - val_loss: 0.8161 - 41s/epoch - 794us/step\n",
      "Epoch 88/100\n",
      "51232/51232 - 41s - loss: 0.8033 - val_loss: 0.8170 - 41s/epoch - 791us/step\n",
      "Epoch 89/100\n",
      "51232/51232 - 40s - loss: 0.8034 - val_loss: 0.8147 - 40s/epoch - 775us/step\n",
      "Epoch 90/100\n",
      "51232/51232 - 40s - loss: 0.8031 - val_loss: 0.8341 - 40s/epoch - 779us/step\n",
      "Epoch 91/100\n",
      "51232/51232 - 40s - loss: 0.8032 - val_loss: 0.8191 - 40s/epoch - 774us/step\n",
      "Epoch 92/100\n",
      "51232/51232 - 40s - loss: 0.8028 - val_loss: 0.8088 - 40s/epoch - 789us/step\n",
      "Epoch 93/100\n",
      "51232/51232 - 39s - loss: 0.8027 - val_loss: 0.8296 - 39s/epoch - 765us/step\n",
      "Epoch 94/100\n",
      "51232/51232 - 40s - loss: 0.8026 - val_loss: 0.8228 - 40s/epoch - 777us/step\n",
      "Epoch 95/100\n",
      "51232/51232 - 40s - loss: 0.8037 - val_loss: 0.8089 - 40s/epoch - 771us/step\n",
      "Epoch 96/100\n",
      "51232/51232 - 40s - loss: 0.8029 - val_loss: 0.8118 - 40s/epoch - 774us/step\n",
      "Epoch 97/100\n",
      "51232/51232 - 40s - loss: 0.8029 - val_loss: 0.8128 - 40s/epoch - 775us/step\n",
      "Epoch 98/100\n",
      "51232/51232 - 40s - loss: 0.8035 - val_loss: 0.8201 - 40s/epoch - 772us/step\n",
      "Epoch 99/100\n",
      "51232/51232 - 39s - loss: 0.8032 - val_loss: 0.8211 - 39s/epoch - 765us/step\n",
      "Epoch 100/100\n",
      "51232/51232 - 40s - loss: 0.8021 - val_loss: 0.8089 - 40s/epoch - 774us/step\n",
      "12808/12808 [==============================] - 7s 516us/step\n",
      "DNN RMSE: 0.8993953649369955\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))\n",
    "dnn_model.add(Dropout(0.2))\n",
    "dnn_model.add(Dense(64, activation='relu'))\n",
    "dnn_model.add(Dense(1))\n",
    "dnn_model.compile(optimizer='adam', loss='mse')\n",
    "dnn_model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), verbose=2)\n",
    "dnn_predictions = dnn_model.predict(X_test).flatten()\n",
    "dnn_rmse = np.sqrt(mean_squared_error(y_test, dnn_predictions))\n",
    "print(f\"DNN RMSE: {dnn_rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f447b172-6a67-40ef-951c-7d95cc9117e0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n",
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "12 fits failed out of a total of 24.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "9 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 732, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1144, in wrapper\n",
      "    estimator._validate_params()\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 637, in _validate_params\n",
      "    validate_parameter_constraints(\n",
      "  File \"C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py\", line 95, in validate_parameter_constraints\n",
      "    raise InvalidParameterError(\n",
      "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestRegressor must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:976: UserWarning: One or more of the test scores are non-finite: [        nan         nan -0.88452461 -0.88513267         nan         nan\n",
      " -0.78460464 -0.78436036]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest - Best Params: {'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': 10}, RMSE: 0.8901836707859893\n",
      "GradientBoosting - Best Params: {'learning_rate': 0.1, 'max_depth': 4, 'n_estimators': 200}, RMSE: 0.891527470007352\n",
      "Ridge - Best Params: {'alpha': 100}, RMSE: 1.0182476148908415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yatish\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:307: UserWarning: The total space of parameters 8 is smaller than n_iter=10. Running 8 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Load and preprocess the dataset\n",
    "data = pd.read_csv('household_power_consumption.txt', delimiter=';', na_values=['nan', '?'])\n",
    "data['Datetime'] = pd.to_datetime(data['Date'] + ' ' + data['Time'], dayfirst=True)\n",
    "data.set_index('Datetime', inplace=True)\n",
    "data.drop(['Date', 'Time'], axis=1, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "sampled_data = data.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Feature engineering\n",
    "sampled_data['hour'] = sampled_data.index.hour\n",
    "sampled_data['day_of_week'] = sampled_data.index.dayofweek\n",
    "sampled_data['month'] = sampled_data.index.month\n",
    "X_sample = sampled_data[['hour', 'day_of_week', 'month']]\n",
    "y_sample = sampled_data['Global_active_power']\n",
    "\n",
    "# Split the data\n",
    "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sample, y_sample, test_size=0.2, random_state=42)\n",
    "\n",
    "# Model training and evaluation\n",
    "models = {\n",
    "    'RandomForest': (RandomForestRegressor(), {'n_estimators': [100, 200], 'max_features': ['auto', 'sqrt'], 'max_depth': [5, 10]}),\n",
    "    'GradientBoosting': (GradientBoostingRegressor(), {'n_estimators': [100, 200], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 4]}),\n",
    "    'Ridge': (Ridge(), {'alpha': [1e-3, 1e-2, 1e-1, 1, 10, 100]}),\n",
    "    'SVR': (SVR(), {'C': [0.1, 1], 'gamma': [1, 0.1], 'kernel': ['rbf', 'poly']}),\n",
    "    'MLPRegressor': (MLPRegressor(), {'hidden_layer_sizes': [(50,), (100,)], 'activation': ['relu', 'tanh'], 'solver': ['adam'], 'alpha': [0.0001, 0.05]}),\n",
    "    'XGBoost': (XGBRegressor(), {'n_estimators': [100, 200, 300], 'learning_rate': [0.01, 0.1, 0.2], 'max_depth': [3, 4, 5]})\n",
    "}\n",
    "\n",
    "for model_name, (model, params) in models.items():\n",
    "    if model_name in ['RandomForest', 'SVR', 'MLPRegressor', 'XGBoost']:\n",
    "        search = RandomizedSearchCV(model, params, n_iter=10, cv=3, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
    "    else:\n",
    "        search = GridSearchCV(model, params, cv=3, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    search.fit(X_train_sample, y_train_sample)\n",
    "    best_model = search.best_estimator_\n",
    "    predictions = best_model.predict(X_test_sample)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test_sample, predictions))\n",
    "    print(f\"{model_name} - Best Params: {search.best_params_}, RMSE: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f480bc88-affc-4cbf-a044-dd7a54c4ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01cb23b9-7f23-4f06-8872-29f573726035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForest\n",
    "rf_model = RandomForestRegressor()\n",
    "rf_params = {'n_estimators': [300, 400], 'max_depth': [20, 25], 'min_samples_split': [4, 6], 'min_samples_leaf': [1, 2]}\n",
    "rf_search = GridSearchCV(rf_model, rf_params, cv=3, scoring='neg_mean_squared_error')\n",
    "rf_search.fit(X_train_poly, y_train)\n",
    "rf_best = rf_search.best_estimator_\n",
    "rf_predictions = rf_best.predict(X_test_poly)\n",
    "rf_rmse = np.sqrt(mean_squared_error(y_test, rf_predictions))\n",
    "print(f\"RandomForest RMSE: {rf_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc314f17-a681-408b-a17b-16503f41ecec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoosting\n",
    "gb_model = GradientBoostingRegressor()\n",
    "gb_params = {'n_estimators': [300, 400], 'learning_rate': [0.05, 0.1], 'max_depth': [5, 6]}\n",
    "gb_search = GridSearchCV(gb_model, gb_params, cv=3, scoring='neg_mean_squared_error')\n",
    "gb_search.fit(X_train_poly, y_train)\n",
    "gb_best = gb_search.best_estimator_\n",
    "gb_predictions = gb_best.predict(X_test_poly)\n",
    "gb_rmse = np.sqrt(mean_squared_error(y_test, gb_predictions))\n",
    "print(f\"GradientBoosting RMSE: {gb_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dfd0bf5-42ec-4dc8-aebb-5a4df9ba0d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ridge\n",
    "ridge_model = Ridge()\n",
    "ridge_params = {'alpha': [1000, 10000]}\n",
    "ridge_search = GridSearchCV(ridge_model, ridge_params, cv=3, scoring='neg_mean_squared_error')\n",
    "ridge_search.fit(X_train_poly, y_train)\n",
    "ridge_best = ridge_search.best_estimator_\n",
    "ridge_predictions = ridge_best.predict(X_test_poly)\n",
    "ridge_rmse = np.sqrt(mean_squared_error(y_test, ridge_predictions))\n",
    "print(f\"Ridge RMSE: {ridge_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11122445-7833-45ee-87bf-2c4762e86e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "dnn_model = Sequential()\n",
    "dnn_model.add(Dense(128, activation='relu', input_dim=X_train_poly.shape[1]))\n",
    "dnn_model.add(Dropout(0.2))\n",
    "dnn_model.add(Dense(64, activation='relu'))\n",
    "dnn_model.add(Dense(1))\n",
    "dnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "dnn_model.fit(X_train_poly, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "dnn_predictions = dnn_model.predict(X_test_poly).flatten()\n",
    "dnn_rmse = np.sqrt(mean_squared_error(y_test, dnn_predictions))\n",
    "print(f\"DNN RMSE: {dnn_rmse}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
